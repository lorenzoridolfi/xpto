diff --git a/python/packages/autogen-core/src/autogen_core/models/_model_client.py b/python/packages/autogen-core/src/autogen_core/models/_model_client.py
index dac7b4daa..47854da94 100644
--- a/python/packages/autogen-core/src/autogen_core/models/_model_client.py
+++ b/python/packages/autogen-core/src/autogen_core/models/_model_client.py
@@ -37,15 +37,9 @@ class ModelFamily:
     CLAUDE_3_5_HAIKU = "claude-3-5-haiku"
     CLAUDE_3_5_SONNET = "claude-3-5-sonnet"
     CLAUDE_3_7_SONNET = "claude-3-7-sonnet"
-    CODESRAL = "codestral"
-    OPEN_CODESRAL_MAMBA = "open-codestral-mamba"
-    MISTRAL = "mistral"
-    MINISTRAL = "ministral"
-    PIXTRAL = "pixtral"
     UNKNOWN = "unknown"
 
     ANY: TypeAlias = Literal[
-        # openai_models
         "gpt-41",
         "gpt-45",
         "gpt-4o",
@@ -55,25 +49,16 @@ class ModelFamily:
         "gpt-4",
         "gpt-35",
         "r1",
-        # google_models
         "gemini-1.5-flash",
         "gemini-1.5-pro",
         "gemini-2.0-flash",
         "gemini-2.5-pro",
-        # anthropic_models
         "claude-3-haiku",
         "claude-3-sonnet",
         "claude-3-opus",
         "claude-3-5-haiku",
         "claude-3-5-sonnet",
         "claude-3-7-sonnet",
-        # mistral_models
-        "codestral",
-        "open-codestral-mamba",
-        "mistral",
-        "ministral",
-        "pixtral",
-        # unknown
         "unknown",
     ]
 
@@ -103,26 +88,13 @@ def is_gemini(family: str) -> bool:
     @staticmethod
     def is_openai(family: str) -> bool:
         return family in (
-            ModelFamily.GPT_45,
-            ModelFamily.GPT_41,
             ModelFamily.GPT_4O,
             ModelFamily.O1,
             ModelFamily.O3,
-            ModelFamily.O4,
             ModelFamily.GPT_4,
             ModelFamily.GPT_35,
         )
 
-    @staticmethod
-    def is_mistral(family: str) -> bool:
-        return family in (
-            ModelFamily.CODESRAL,
-            ModelFamily.OPEN_CODESRAL_MAMBA,
-            ModelFamily.MISTRAL,
-            ModelFamily.MINISTRAL,
-            ModelFamily.PIXTRAL,
-        )
-
 
 @deprecated("Use the ModelInfo class instead ModelCapabilities.")
 class ModelCapabilities(TypedDict, total=False):
@@ -148,8 +120,6 @@ class ModelInfo(TypedDict, total=False):
     """Model family should be one of the constants from :py:class:`ModelFamily` or a string representing an unknown model family."""
     structured_output: Required[bool]
     """True if the model supports structured output, otherwise False. This is different to json_output."""
-    multiple_system_messages: Optional[bool]
-    """True if the model supports multiple, non-consecutive system messages, otherwise False."""
 
 
 def validate_model_info(model_info: ModelInfo) -> None:
diff --git a/python/packages/autogen-ext/src/autogen_ext/models/anthropic/_model_info.py b/python/packages/autogen-ext/src/autogen_ext/models/anthropic/_model_info.py
index 27b6dd68a..8959e7c74 100644
--- a/python/packages/autogen-ext/src/autogen_ext/models/anthropic/_model_info.py
+++ b/python/packages/autogen-ext/src/autogen_ext/models/anthropic/_model_info.py
@@ -1,131 +1,358 @@
+import logging
 from typing import Dict
 
+from autogen_core import EVENT_LOGGER_NAME, TRACE_LOGGER_NAME
 from autogen_core.models import ModelFamily, ModelInfo
 
-# Mapping of model names to their capabilities
-# For Anthropic's Claude models based on:
-# https://docs.anthropic.com/claude/docs/models-overview
+logger = logging.getLogger(EVENT_LOGGER_NAME)
+trace_logger = logging.getLogger(TRACE_LOGGER_NAME)
+
+# Based on: https://platform.openai.com/docs/models/continuous-model-upgrades
+# This is a moving target, so correctness is checked by the model value returned by openai against expected values at runtime``
+_MODEL_POINTERS = {
+    # OpenAI models
+    "o4-mini": "o4-mini-2025-04-16",
+    "o3": "o3-2025-04-16",
+    "o3-mini": "o3-mini-2025-01-31",
+    "o1": "o1-2024-12-17",
+    "o1-preview": "o1-preview-2024-09-12",
+    "o1-mini": "o1-mini-2024-09-12",
+    "gpt-4.1": "gpt-4.1-2025-04-14",
+    "gpt-4.5-preview": "gpt-4.5-preview-2025-02-27",
+    "gpt-4o": "gpt-4o-2024-08-06",
+    "gpt-4o-mini": "gpt-4o-mini-2024-07-18",
+    "gpt-4-turbo": "gpt-4-turbo-2024-04-09",
+    "gpt-4-turbo-preview": "gpt-4-0125-preview",
+    "gpt-4": "gpt-4-0613",
+    "gpt-4-32k": "gpt-4-32k-0613",
+    "gpt-3.5-turbo": "gpt-3.5-turbo-0125",
+    "gpt-3.5-turbo-16k": "gpt-3.5-turbo-16k-0613",
+    # Anthropic models
+    "claude-3-haiku": "claude-3-haiku-20240307",
+    "claude-3-sonnet": "claude-3-sonnet-20240229",
+    "claude-3-opus": "claude-3-opus-20240229",
+    "claude-3-5-haiku": "claude-3-5-haiku-20241022",
+    "claude-3-5-sonnet": "claude-3-5-sonnet-20241022",
+    "claude-3-7-sonnet": "claude-3-7-sonnet-20250219",
+}
+
 _MODEL_INFO: Dict[str, ModelInfo] = {
-    # Claude 3.7 Sonnet
-    "claude-3-7-sonnet-20250219": {
+    "o4-mini-2025-04-16": {
         "vision": True,
         "function_calling": True,
         "json_output": True,
-        "family": ModelFamily.CLAUDE_3_7_SONNET,
-        "structured_output": False,
-        "multiple_system_messages": False,
+        "family": ModelFamily.O4,
+        "structured_output": True,
     },
-    # Claude 3.7 Sonnet latest alias
-    "claude-3-7-sonnet-latest": {
+    "o3-2025-04-16": {
         "vision": True,
         "function_calling": True,
         "json_output": True,
-        "family": ModelFamily.CLAUDE_3_7_SONNET,
+        "family": ModelFamily.O3,
+        "structured_output": True,
+    },
+    "o3-mini-2025-01-31": {
+        "vision": False,
+        "function_calling": True,
+        "json_output": True,
+        "family": ModelFamily.O3,
+        "structured_output": True,
+    },
+    "o1-2024-12-17": {
+        "vision": False,
+        "function_calling": False,
+        "json_output": False,
+        "family": ModelFamily.O1,
+        "structured_output": True,
+    },
+    "o1-preview-2024-09-12": {
+        "vision": False,
+        "function_calling": False,
+        "json_output": False,
+        "family": ModelFamily.O1,
+        "structured_output": True,
+    },
+    "o1-mini-2024-09-12": {
+        "vision": False,
+        "function_calling": False,
+        "json_output": False,
+        "family": ModelFamily.O1,
         "structured_output": False,
-        "multiple_system_messages": False,
     },
-    # Claude 3 Opus (most powerful)
-    "claude-3-opus-20240229": {
+    "gpt-4.1-2025-04-14": {
         "vision": True,
         "function_calling": True,
         "json_output": True,
-        "family": ModelFamily.CLAUDE_3_5_SONNET,
-        "structured_output": False,
-        "multiple_system_messages": False,
+        "family": ModelFamily.GPT_41,
+        "structured_output": True,
     },
-    # Claude 3 Sonnet (balanced)
-    "claude-3-sonnet-20240229": {
+    "gpt-4.5-preview-2025-02-27": {
         "vision": True,
         "function_calling": True,
         "json_output": True,
-        "family": ModelFamily.CLAUDE_3_5_SONNET,
-        "structured_output": False,
-        "multiple_system_messages": False,
+        "family": ModelFamily.GPT_45,
+        "structured_output": True,
     },
-    # Claude 3 Haiku (fastest)
-    "claude-3-haiku-20240307": {
+    "gpt-4o-2024-11-20": {
         "vision": True,
         "function_calling": True,
         "json_output": True,
-        "family": ModelFamily.CLAUDE_3_5_SONNET,
+        "family": ModelFamily.GPT_4O,
+        "structured_output": True,
+    },
+    "gpt-4o-2024-08-06": {
+        "vision": True,
+        "function_calling": True,
+        "json_output": True,
+        "family": ModelFamily.GPT_4O,
+        "structured_output": True,
+    },
+    "gpt-4o-2024-05-13": {
+        "vision": True,
+        "function_calling": True,
+        "json_output": True,
+        "family": ModelFamily.GPT_4O,
         "structured_output": False,
-        "multiple_system_messages": False,
     },
-    # Claude 3.5 Sonnet
-    "claude-3-5-sonnet-20240620": {
+    "gpt-4o-mini-2024-07-18": {
         "vision": True,
         "function_calling": True,
         "json_output": True,
-        "family": ModelFamily.CLAUDE_3_5_SONNET,
+        "family": ModelFamily.GPT_4O,
+        "structured_output": True,
+    },
+    "gpt-4-turbo-2024-04-09": {
+        "vision": True,
+        "function_calling": True,
+        "json_output": True,
+        "family": ModelFamily.GPT_4,
         "structured_output": False,
-        "multiple_system_messages": False,
     },
-    # Claude Instant v1 (legacy)
-    "claude-instant-1.2": {
+    "gpt-4-0125-preview": {
         "vision": False,
-        "function_calling": False,
+        "function_calling": True,
         "json_output": True,
-        "family": ModelFamily.CLAUDE_3_5_SONNET,
+        "family": ModelFamily.GPT_4,
         "structured_output": False,
-        "multiple_system_messages": False,
     },
-    # Claude 2 (legacy)
-    "claude-2.0": {
+    "gpt-4-1106-preview": {
         "vision": False,
+        "function_calling": True,
+        "json_output": True,
+        "family": ModelFamily.GPT_4,
+        "structured_output": False,
+    },
+    "gpt-4-1106-vision-preview": {
+        "vision": True,
         "function_calling": False,
+        "json_output": False,
+        "family": ModelFamily.GPT_4,
+        "structured_output": False,
+    },
+    "gpt-4-0613": {
+        "vision": False,
+        "function_calling": True,
         "json_output": True,
-        "family": ModelFamily.CLAUDE_3_5_SONNET,
+        "family": ModelFamily.GPT_4,
         "structured_output": False,
-        "multiple_system_messages": False,
     },
-    # Claude 2.1 (legacy)
-    "claude-2.1": {
+    "gpt-4-32k-0613": {
         "vision": False,
-        "function_calling": False,
+        "function_calling": True,
+        "json_output": True,
+        "family": ModelFamily.GPT_4,
+        "structured_output": False,
+    },
+    "gpt-3.5-turbo-0125": {
+        "vision": False,
+        "function_calling": True,
+        "json_output": True,
+        "family": ModelFamily.GPT_35,
+        "structured_output": False,
+    },
+    "gpt-3.5-turbo-1106": {
+        "vision": False,
+        "function_calling": True,
+        "json_output": True,
+        "family": ModelFamily.GPT_35,
+        "structured_output": False,
+    },
+    "gpt-3.5-turbo-instruct": {
+        "vision": False,
+        "function_calling": True,
+        "json_output": True,
+        "family": ModelFamily.GPT_35,
+        "structured_output": False,
+    },
+    "gpt-3.5-turbo-0613": {
+        "vision": False,
+        "function_calling": True,
+        "json_output": True,
+        "family": ModelFamily.GPT_35,
+        "structured_output": False,
+    },
+    "gpt-3.5-turbo-16k-0613": {
+        "vision": False,
+        "function_calling": True,
         "json_output": True,
+        "family": ModelFamily.GPT_35,
+        "structured_output": False,
+    },
+    "gemini-1.5-flash": {
+        "vision": True,
+        "function_calling": True,
+        "json_output": True,
+        "family": ModelFamily.GEMINI_1_5_FLASH,
+        "structured_output": True,
+    },
+    "gemini-1.5-flash-8b": {
+        "vision": True,
+        "function_calling": True,
+        "json_output": True,
+        "family": ModelFamily.GEMINI_1_5_FLASH,
+        "structured_output": True,
+    },
+    "gemini-1.5-pro": {
+        "vision": True,
+        "function_calling": True,
+        "json_output": True,
+        "family": ModelFamily.GEMINI_1_5_PRO,
+        "structured_output": True,
+    },
+    "gemini-2.0-flash": {
+        "vision": True,
+        "function_calling": True,
+        "json_output": True,
+        "family": ModelFamily.GEMINI_2_0_FLASH,
+        "structured_output": True,
+    },
+    "gemini-2.0-flash-lite-preview-02-05": {
+        "vision": True,
+        "function_calling": True,
+        "json_output": True,
+        "family": ModelFamily.GEMINI_2_0_FLASH,
+        "structured_output": True,
+    },
+    "gemini-2.5-pro-preview-03-25": {
+        "vision": True,
+        "function_calling": True,
+        "json_output": True,
+        "family": ModelFamily.GEMINI_2_5_PRO,
+        "structured_output": True,
+    },
+    "claude-3-haiku-20240307": {
+        "vision": True,
+        "function_calling": True,
+        "json_output": False,  # Update this when Anthropic supports structured output
+        "family": ModelFamily.CLAUDE_3_HAIKU,
+        "structured_output": False,
+    },
+    "claude-3-sonnet-20240229": {
+        "vision": True,
+        "function_calling": True,
+        "json_output": False,  # Update this when Anthropic supports structured output
+        "family": ModelFamily.CLAUDE_3_SONNET,
+        "structured_output": False,
+    },
+    "claude-3-opus-20240229": {
+        "vision": True,
+        "function_calling": True,
+        "json_output": False,  # Update this when Anthropic supports structured output
+        "family": ModelFamily.CLAUDE_3_OPUS,
+        "structured_output": False,
+    },
+    "claude-3-5-haiku-20241022": {
+        "vision": True,
+        "function_calling": True,
+        "json_output": False,  # Update this when Anthropic supports structured output
+        "family": ModelFamily.CLAUDE_3_5_HAIKU,
+        "structured_output": False,
+    },
+    "claude-3-5-sonnet-20241022": {
+        "vision": True,
+        "function_calling": True,
+        "json_output": False,  # Update this when Anthropic supports structured output
         "family": ModelFamily.CLAUDE_3_5_SONNET,
         "structured_output": False,
-        "multiple_system_messages": False,
+    },
+    "claude-3-7-sonnet-20250219": {
+        "vision": True,
+        "function_calling": True,
+        "json_output": False,  # Update this when Anthropic supports structured output
+        "family": ModelFamily.CLAUDE_3_7_SONNET,
+        "structured_output": False,
     },
 }
 
-# Model token limits (context window size)
 _MODEL_TOKEN_LIMITS: Dict[str, int] = {
-    "claude-3-opus-20240229": 200000,
-    "claude-3-sonnet-20240229": 200000,
-    "claude-3-haiku-20240307": 200000,
-    "claude-3-5-sonnet-20240620": 200000,
-    "claude-3-7-sonnet-20250219": 200000,
-    "claude-instant-1.2": 100000,
-    "claude-2.0": 100000,
-    "claude-2.1": 200000,
+    "o4-mini-2025-04-16": 200000,
+    "o3-2025-04-16": 200000,
+    "o3-mini-2025-01-31": 200000,
+    "o1-2024-12-17": 200000,
+    "o1-preview-2024-09-12": 128000,
+    "o1-mini-2024-09-12": 128000,
+    "gpt-4.1-2025-04-14": 1047576,
+    "gpt-4.5-preview-2025-02-27": 128000,
+    "gpt-4o-2024-11-20": 128000,
+    "gpt-4o-2024-08-06": 128000,
+    "gpt-4o-2024-05-13": 128000,
+    "gpt-4o-mini-2024-07-18": 128000,
+    "gpt-4-turbo-2024-04-09": 128000,
+    "gpt-4-0125-preview": 128000,
+    "gpt-4-1106-preview": 128000,
+    "gpt-4-1106-vision-preview": 128000,
+    "gpt-4-0613": 8192,
+    "gpt-4-32k-0613": 32768,
+    "gpt-3.5-turbo-0125": 16385,
+    "gpt-3.5-turbo-1106": 16385,
+    "gpt-3.5-turbo-instruct": 4096,
+    "gpt-3.5-turbo-0613": 4096,
+    "gpt-3.5-turbo-16k-0613": 16385,
+    "gemini-1.5-flash": 1048576,
+    "gemini-1.5-flash-8b": 1048576,
+    "gemini-1.5-pro": 2097152,
+    "gemini-2.0-flash": 1048576,
+    "gemini-2.0-flash-lite-preview-02-05": 1048576,
+    "gemini-2.5-pro-preview-03-25": 2097152,
+    "claude-3-haiku-20240307": 50000,
+    "claude-3-sonnet-20240229": 40000,
+    "claude-3-opus-20240229": 20000,
+    "claude-3-5-haiku-20241022": 50000,
+    "claude-3-5-sonnet-20241022": 40000,
+    "claude-3-7-sonnet-20250219": 20000,
 }
 
+GEMINI_OPENAI_BASE_URL = "https://generativelanguage.googleapis.com/v1beta/openai/"
+ANTHROPIC_OPENAI_BASE_URL = "https://api.anthropic.com/v1/"
 
-def get_info(model: str) -> ModelInfo:
-    """Get the model information for a specific model."""
-    # Check for exact match first
-    if model in _MODEL_INFO:
-        return _MODEL_INFO[model]
 
-    # Check for partial match (for handling model variants)
-    for model_id in _MODEL_INFO:
-        if model.startswith(model_id.split("-2")[0]):  # Match base name
-            return _MODEL_INFO[model_id]
+def resolve_model(model: str) -> str:
+    if model in _MODEL_POINTERS:
+        return _MODEL_POINTERS[model]
+    return model
 
-    raise KeyError(f"Model '{model}' not found in model info")
 
+def get_info(model: str) -> ModelInfo:
+    # If call it, that mean is that the config does not have cumstom model_info
+    resolved_model = resolve_model(model)
+    model_info: ModelInfo = _MODEL_INFO.get(
+        resolved_model,
+        {
+            "vision": False,
+            "function_calling": False,
+            "json_output": False,
+            "family": "FAILED",
+            "structured_output": False,
+        },
+    )
+    if model_info.get("family") == "FAILED":
+        raise ValueError("model_info is required when model name is not a valid OpenAI model")
+    if model_info.get("family") == ModelFamily.UNKNOWN:
+        trace_logger.warning(f"Model info not found for model: {model}")
 
-def get_token_limit(model: str) -> int:
-    """Get the token limit for a specific model."""
-    # Check for exact match first
-    if model in _MODEL_TOKEN_LIMITS:
-        return _MODEL_TOKEN_LIMITS[model]
+    return model_info
 
-    # Check for partial match (for handling model variants)
-    for model_id in _MODEL_TOKEN_LIMITS:
-        if model.startswith(model_id.split("-2")[0]):  # Match base name
-            return _MODEL_TOKEN_LIMITS[model_id]
 
-    # Default to a reasonable limit if model not found
-    return 100000
+def get_token_limit(model: str) -> int:
+    resolved_model = resolve_model(model)
+    return _MODEL_TOKEN_LIMITS[resolved_model]
